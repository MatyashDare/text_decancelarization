{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb862a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b03845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 30 12:39:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.172.01   Driver Version: 450.172.01   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:59:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    53W / 350W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8502545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe2b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 12:39:28.269807: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7b0562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4a114b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>path</th>\n",
       "      <th>original</th>\n",
       "      <th>new</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>131</td>\n",
       "      <td>0024c525-9f48-4e21-8eec-d00aea56deaa</td>\n",
       "      <td>В целях продвижения нового канала продаж «Цифр...</td>\n",
       "      <td>Цель продвижения  канала продаж «Цифровой офис...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1119</td>\n",
       "      <td>1184</td>\n",
       "      <td>00e3fe8f-114e-4b83-a15f-aa7af38f931a</td>\n",
       "      <td>в разрезе центров прибыли верхнего уровня:</td>\n",
       "      <td>по прибыли верхнего уровня:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1033</td>\n",
       "      <td>1123</td>\n",
       "      <td>00e19c69-1d75-4459-b4e3-8256a6fbdaf3</td>\n",
       "      <td>в срок до 16.12.2021 включительно сформировать...</td>\n",
       "      <td>до 16.12.2021 определить победителей Акции;</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                  path  \\\n",
       "0         118    131  0024c525-9f48-4e21-8eec-d00aea56deaa   \n",
       "1        1119   1184  00e3fe8f-114e-4b83-a15f-aa7af38f931a   \n",
       "2        1033   1123  00e19c69-1d75-4459-b4e3-8256a6fbdaf3   \n",
       "\n",
       "                                            original  \\\n",
       "0  В целях продвижения нового канала продаж «Цифр...   \n",
       "1         в разрезе центров прибыли верхнего уровня:   \n",
       "2  в срок до 16.12.2021 включительно сформировать...   \n",
       "\n",
       "                                                 new  var  \n",
       "0  Цель продвижения  канала продаж «Цифровой офис...    4  \n",
       "1                        по прибыли верхнего уровня:    1  \n",
       "2        до 16.12.2021 определить победителей Акции;    4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/markup2train.csv')\n",
    "test_df = pd.read_csv('../data/markup2test.csv')\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335d9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrase_token = '<DECANC>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f234c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['original'] = train_df['original'] + rephrase_token\n",
    "test_df['original'] = test_df['original'] + rephrase_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a45323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в разрезе центров прибыли верхнего уровня:<DECANC>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['original'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51f55bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5841, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=train_df[train_df['new'].isna()==False].reset_index()\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35348daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, x, y):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.x['input_ids'][idx] + self.y['input_ids'][idx]\n",
    "        attention_mask = self.x['attention_mask'][idx] + self.y['attention_mask'][idx]\n",
    "        labels = [self.tokenizer.pad_token_id] * len(self.x['input_ids'][idx]) + self.y['input_ids'][idx]\n",
    "        item = {\"input_ids\": inp, \"attention_mask\" : attention_mask, \"labels\": labels}\n",
    "        return item\n",
    "    \n",
    "    @property\n",
    "    def n(self):\n",
    "        return len(self.x['input_ids'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n # * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad52470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.file_utils import cached_property\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c69c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=True,\n",
    "        )\n",
    "        ybatch = self.tokenizer.pad(\n",
    "            {'input_ids': batch['labels'], 'attention_mask': batch['attention_mask']},\n",
    "            padding=True,\n",
    "        ) \n",
    "        # ybatch['input_ids'][ybatch['input_ids'] == tokenizer.pad_token_id] = -100\n",
    "        batch['labels'] = ybatch['input_ids']\n",
    "        return {k: torch.tensor(v) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "decf27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b0ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, test_dataloader):\n",
    "    num = 0\n",
    "    den = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            batch['labels'][batch['labels']==tokenizer.pad_token_id] = -100\n",
    "            loss = model(**{k: v.to(model.device) for k, v in batch.items()}).loss\n",
    "            num += len(batch) * loss.item()\n",
    "            den += len(batch)\n",
    "    val_loss = num / den\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6c4355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "ce = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "    model, tokenizer, train_dataloader, val_dataloader, \n",
    "    lr=3e-5,\n",
    "    weight_decay=1e-2,\n",
    "    max_epochs=10,\n",
    "    gradient_accumulation_steps=1, \n",
    "    early_stop_round=2\n",
    "):\n",
    "    cleanup()\n",
    "    print(f\"LR = {lr}, weight_decay={weight_decay}\")\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    ewm_loss = 0\n",
    "    step = 0\n",
    "    best_model = None\n",
    "    model.train()\n",
    "    best_eval = float('inf')\n",
    "    es = 0\n",
    "    for epoch in trange(max_epochs):\n",
    "        tq = tqdm(train_dataloader)\n",
    "        for i, batch in enumerate(tq):\n",
    "            try:\n",
    "                batch['labels'][batch['labels']==tokenizer.pad_token_id] = -100\n",
    "                loss = model(**{k: v.to(model.device) for k, v in batch.items()}).loss\n",
    "#                 output = model(**{k: v.to(model.device) for k, v in batch.items()})\n",
    "#                 output = model(**batch)\n",
    "#                 logits = output.logits\n",
    "#                 labels = batch['labels']\n",
    "#                 ce_result = ce(logits.permute(0, 2, 1), labels)\n",
    "#                 probs = (torch.nn.functional.one_hot(labels, logits.shape[2]) * torch.nn.functional.softmax(logits, dim=2)).sum(2)\n",
    "#                 loss = (((1 - probs) ** 2) * ce_result).mean()\n",
    "                loss.backward()\n",
    "            except Exception as e:\n",
    "                print('error on step', i, e)\n",
    "                loss = None\n",
    "                cleanup()\n",
    "                continue\n",
    "#             if i and i % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            for p in model.parameters():\n",
    "                p.grad = None\n",
    "#             optimizer.zero_grad()\n",
    "            step += 1\n",
    "\n",
    "            ewm_loss = loss.item()\n",
    "            tq.set_description(f'loss: {ewm_loss:4.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = evaluate_model(model, tokenizer, val_dataloader)\n",
    "        model.train()\n",
    "        print(f'epoch {epoch}, step {i}/{step}: train loss: {ewm_loss:4.4f}  val loss: {eval_loss:4.4f}')\n",
    "        if eval_loss < best_eval:\n",
    "            es = 0\n",
    "            best_eval = eval_loss\n",
    "            best_model = deepcopy(model)\n",
    "            print(\"New best pretrain_iteration\")\n",
    "        else:\n",
    "            es += 1\n",
    "        if es == early_stop_round:\n",
    "            print(\"Early Stop!\")\n",
    "            break\n",
    "        cleanup()\n",
    "    cleanup()\n",
    "    return best_eval, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a5c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, model_name, test_size=0.1, batch_size=32, **kwargs):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    tokenizer.add_special_tokens(\n",
    "        {'additional_special_tokens': [rephrase_token], 'pad_token': '[PAD]'}\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "\n",
    "    x1, x2, y1, y2 = train_test_split(x, y, test_size=test_size, random_state=42)\n",
    "    train_dataset = GPTDataset(tokenizer, tokenizer(x1), tokenizer(y1))\n",
    "    test_dataset = GPTDataset(tokenizer, tokenizer(x2), tokenizer(y2))\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True, collate_fn=data_collator, pin_memory=True)\n",
    "    val_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=True, collate_fn=data_collator, pin_memory=True)\n",
    "\n",
    "    eval_loss, best_model = train_loop(model, tokenizer, train_dataloader, val_dataloader, **kwargs)\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b21050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': train_df[['original', 'new']],\n",
    "    'test': test_df[['original', 'new']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "431663b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'sberbank-ai/rugpt3large_based_on_gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b6df577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1785b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    print(f'Trial {trial.number} is started')\n",
    "    lr = trial.suggest_float(\"lr\", 1e-7, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1, log=True)\n",
    "    seed = 0\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    d = datasets['train']\n",
    "    dname = 'train'\n",
    "    print(f'\\n\\n\\n  train \\n=====================\\n\\n')\n",
    "    eval_loss = train_model(d['original'].tolist(),\n",
    "                            d['new'].tolist(),\n",
    "                            model_name=model_name,\n",
    "                            batch_size=16,\n",
    "                            lr=lr,\n",
    "                            weight_decay=weight_decay,\n",
    "                            )\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8ddfb313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=55, values=[4.286579264534844], datetime_start=datetime.datetime(2022, 5, 22, 0, 15, 29, 157451), datetime_complete=datetime.datetime(2022, 5, 22, 0, 20, 55, 638675), params={'lr': 9.096840128561833e-05, 'weight_decay': 0.09598965983303268}, distributions={'lr': LogUniformDistribution(high=0.01, low=1e-06), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-07)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=55, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "75c63ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('optuna_history_t5.pkl', 'wb') as f:\n",
    "#     pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e55ef6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('optuna_history_t5.pkl', 'rb') as f:\n",
    "    study = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efc31f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 9.096840128561833e-05, 'weight_decay': 0.09598965983303268}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94202878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(x, y, model_name, test_size=0.1, batch_size=32, **kwargs):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    tokenizer.add_special_tokens(\n",
    "        {'additional_special_tokens': [rephrase_token], 'pad_token': '[PAD]'}\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "\n",
    "    x1, x2, y1, y2 = train_test_split(x, y, test_size=test_size, random_state=42)\n",
    "    train_dataset = GPTDataset(tokenizer, tokenizer(x1), tokenizer(y1))\n",
    "    test_dataset = GPTDataset(tokenizer, tokenizer(x2), tokenizer(y2))\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True, collate_fn=data_collator, pin_memory=True)\n",
    "    val_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=True, collate_fn=data_collator, pin_memory=True)\n",
    "\n",
    "    eval_loss, best_model = train_loop(model, tokenizer, train_dataloader, val_dataloader, **kwargs)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fa520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR = 9.096840128561833e-05, weight_decay=0.09598965983303268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032b179c54dc4a679c99844856fa391a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3c243b8e714b61ab441cdd2435fa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on step 0 CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 31.75 GiB total capacity; 18.88 GiB already allocated; 4.25 MiB free; 19.00 GiB reserved in total by PyTorch)\n",
      "error on step 2 CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 31.75 GiB total capacity; 16.56 GiB already allocated; 1.15 GiB free; 17.85 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 4 CUDA out of memory. Tried to allocate 1.17 GiB (GPU 0; 31.75 GiB total capacity; 16.10 GiB already allocated; 348.25 MiB free; 18.66 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 12 CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 31.75 GiB total capacity; 18.00 GiB already allocated; 20.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 44 CUDA out of memory. Tried to allocate 1.48 GiB (GPU 0; 31.75 GiB total capacity; 17.43 GiB already allocated; 428.25 MiB free; 18.58 GiB reserved in total by PyTorch)\n",
      "error on step 47 CUDA out of memory. Tried to allocate 1.25 GiB (GPU 0; 31.75 GiB total capacity; 16.53 GiB already allocated; 322.25 MiB free; 18.69 GiB reserved in total by PyTorch)\n",
      "error on step 74 CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 31.75 GiB total capacity; 16.82 GiB already allocated; 156.25 MiB free; 18.85 GiB reserved in total by PyTorch)\n",
      "error on step 76 CUDA out of memory. Tried to allocate 1.27 GiB (GPU 0; 31.75 GiB total capacity; 16.92 GiB already allocated; 108.25 MiB free; 18.90 GiB reserved in total by PyTorch)\n",
      "error on step 97 CUDA out of memory. Tried to allocate 202.00 MiB (GPU 0; 31.75 GiB total capacity; 17.53 GiB already allocated; 106.25 MiB free; 18.90 GiB reserved in total by PyTorch)\n",
      "error on step 134 CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 31.75 GiB total capacity; 17.24 GiB already allocated; 106.25 MiB free; 18.90 GiB reserved in total by PyTorch)\n",
      "error on step 140 CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 31.75 GiB total capacity; 16.82 GiB already allocated; 22.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 155 CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 31.75 GiB total capacity; 17.43 GiB already allocated; 22.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 159 CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 31.75 GiB total capacity; 17.55 GiB already allocated; 22.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 162 CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 31.75 GiB total capacity; 17.65 GiB already allocated; 24.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 168 CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 31.75 GiB total capacity; 17.51 GiB already allocated; 22.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 178 CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 31.75 GiB total capacity; 17.51 GiB already allocated; 260.25 MiB free; 18.75 GiB reserved in total by PyTorch)\n",
      "error on step 191 CUDA out of memory. Tried to allocate 1.33 GiB (GPU 0; 31.75 GiB total capacity; 16.51 GiB already allocated; 202.25 MiB free; 18.80 GiB reserved in total by PyTorch)\n",
      "error on step 199 CUDA out of memory. Tried to allocate 1.24 GiB (GPU 0; 31.75 GiB total capacity; 16.48 GiB already allocated; 232.25 MiB free; 18.78 GiB reserved in total by PyTorch)\n",
      "error on step 204 CUDA out of memory. Tried to allocate 1.28 GiB (GPU 0; 31.75 GiB total capacity; 17.00 GiB already allocated; 226.25 MiB free; 18.78 GiB reserved in total by PyTorch)\n",
      "error on step 226 CUDA out of memory. Tried to allocate 1.32 GiB (GPU 0; 31.75 GiB total capacity; 16.37 GiB already allocated; 226.25 MiB free; 18.78 GiB reserved in total by PyTorch)\n",
      "error on step 227 CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 16.77 GiB already allocated; 234.25 MiB free; 18.77 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 238 CUDA out of memory. Tried to allocate 372.00 MiB (GPU 0; 31.75 GiB total capacity; 18.07 GiB already allocated; 102.25 MiB free; 18.90 GiB reserved in total by PyTorch)\n",
      "error on step 272 CUDA out of memory. Tried to allocate 1.33 GiB (GPU 0; 31.75 GiB total capacity; 16.60 GiB already allocated; 762.25 MiB free; 18.26 GiB reserved in total by PyTorch)\n",
      "error on step 276 CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 31.75 GiB total capacity; 18.02 GiB already allocated; 330.25 MiB free; 18.68 GiB reserved in total by PyTorch)\n",
      "error on step 284 CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 31.75 GiB total capacity; 16.53 GiB already allocated; 394.25 MiB free; 18.62 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 288 CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 16.68 GiB already allocated; 390.25 MiB free; 18.62 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 302 CUDA out of memory. Tried to allocate 1.12 GiB (GPU 0; 31.75 GiB total capacity; 15.33 GiB already allocated; 1.07 GiB free; 17.93 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 303 CUDA out of memory. Tried to allocate 1.23 GiB (GPU 0; 31.75 GiB total capacity; 16.34 GiB already allocated; 1.02 GiB free; 17.99 GiB reserved in total by PyTorch)\n",
      "error on step 314 CUDA out of memory. Tried to allocate 1.17 GiB (GPU 0; 31.75 GiB total capacity; 16.04 GiB already allocated; 994.25 MiB free; 18.03 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 326 CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 31.75 GiB total capacity; 17.60 GiB already allocated; 32.25 MiB free; 18.97 GiB reserved in total by PyTorch)\n",
      "epoch 0, step 328/299: train loss: 1.5348  val loss: 0.5358\n",
      "New best pretrain_iteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59caf9239fe14b0e8035789975c7b2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on step 1 CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 17.21 GiB already allocated; 956.25 MiB free; 18.07 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 12 CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 31.75 GiB total capacity; 17.26 GiB already allocated; 84.25 MiB free; 18.92 GiB reserved in total by PyTorch)\n",
      "error on step 16 CUDA out of memory. Tried to allocate 1.48 GiB (GPU 0; 31.75 GiB total capacity; 17.94 GiB already allocated; 414.25 MiB free; 18.60 GiB reserved in total by PyTorch)\n",
      "error on step 18 CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 16.53 GiB already allocated; 240.25 MiB free; 18.77 GiB reserved in total by PyTorch)\n",
      "error on step 34 CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 31.75 GiB total capacity; 17.99 GiB already allocated; 130.25 MiB free; 18.88 GiB reserved in total by PyTorch)\n",
      "error on step 71 CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 31.75 GiB total capacity; 17.65 GiB already allocated; 4.25 MiB free; 19.00 GiB reserved in total by PyTorch)\n",
      "error on step 75 CUDA out of memory. Tried to allocate 1.32 GiB (GPU 0; 31.75 GiB total capacity; 15.57 GiB already allocated; 1.27 GiB free; 17.73 GiB reserved in total by PyTorch)\n",
      "error on step 81 CUDA out of memory. Tried to allocate 1.17 GiB (GPU 0; 31.75 GiB total capacity; 16.56 GiB already allocated; 394.25 MiB free; 18.62 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 99 CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 31.75 GiB total capacity; 17.62 GiB already allocated; 272.25 MiB free; 18.74 GiB reserved in total by PyTorch)\n",
      "error on step 105 CUDA out of memory. Tried to allocate 1.35 GiB (GPU 0; 31.75 GiB total capacity; 17.36 GiB already allocated; 160.25 MiB free; 18.85 GiB reserved in total by PyTorch)\n",
      "error on step 123 CUDA out of memory. Tried to allocate 1.17 GiB (GPU 0; 31.75 GiB total capacity; 16.61 GiB already allocated; 310.25 MiB free; 18.70 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 167 CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 31.75 GiB total capacity; 18.45 GiB already allocated; 56.25 MiB free; 18.95 GiB reserved in total by PyTorch)\n",
      "error on step 182 CUDA out of memory. Tried to allocate 1.33 GiB (GPU 0; 31.75 GiB total capacity; 17.13 GiB already allocated; 1.09 GiB free; 17.92 GiB reserved in total by PyTorch)\n",
      "error on step 185 CUDA out of memory. Tried to allocate 1.24 GiB (GPU 0; 31.75 GiB total capacity; 17.00 GiB already allocated; 1022.25 MiB free; 18.00 GiB reserved in total by PyTorch)\n",
      "error on step 196 CUDA out of memory. Tried to allocate 1.33 GiB (GPU 0; 31.75 GiB total capacity; 17.03 GiB already allocated; 1.02 GiB free; 17.98 GiB reserved in total by PyTorch)\n",
      "error on step 199 CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 31.75 GiB total capacity; 17.76 GiB already allocated; 170.25 MiB free; 18.84 GiB reserved in total by PyTorch)\n",
      "error on step 226 CUDA out of memory. Tried to allocate 1.25 GiB (GPU 0; 31.75 GiB total capacity; 17.05 GiB already allocated; 168.25 MiB free; 18.84 GiB reserved in total by PyTorch)\n",
      "error on step 234 CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 17.20 GiB already allocated; 104.25 MiB free; 18.90 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 242 CUDA out of memory. Tried to allocate 1.24 GiB (GPU 0; 31.75 GiB total capacity; 16.95 GiB already allocated; 206.25 MiB free; 18.80 GiB reserved in total by PyTorch)\n",
      "error on step 267 CUDA out of memory. Tried to allocate 1.19 GiB (GPU 0; 31.75 GiB total capacity; 16.95 GiB already allocated; 398.25 MiB free; 18.61 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 272 CUDA out of memory. Tried to allocate 1.14 GiB (GPU 0; 31.75 GiB total capacity; 16.18 GiB already allocated; 548.25 MiB free; 18.47 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 274 CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 31.75 GiB total capacity; 18.04 GiB already allocated; 236.25 MiB free; 18.77 GiB reserved in total by PyTorch)\n",
      "error on step 283 CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 31.75 GiB total capacity; 17.75 GiB already allocated; 62.25 MiB free; 18.94 GiB reserved in total by PyTorch)\n",
      "error on step 290 CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 31.75 GiB total capacity; 18.23 GiB already allocated; 10.25 MiB free; 18.99 GiB reserved in total by PyTorch)\n",
      "error on step 291 CUDA out of memory. Tried to allocate 1.27 GiB (GPU 0; 31.75 GiB total capacity; 17.44 GiB already allocated; 158.25 MiB free; 18.85 GiB reserved in total by PyTorch)\n",
      "error on step 292 CUDA out of memory. Tried to allocate 1.16 GiB (GPU 0; 31.75 GiB total capacity; 16.37 GiB already allocated; 276.25 MiB free; 18.73 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 302 CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 31.75 GiB total capacity; 17.94 GiB already allocated; 82.25 MiB free; 18.92 GiB reserved in total by PyTorch)\n",
      "error on step 306 CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 31.75 GiB total capacity; 17.99 GiB already allocated; 26.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 308 CUDA out of memory. Tried to allocate 1.27 GiB (GPU 0; 31.75 GiB total capacity; 16.17 GiB already allocated; 1.19 GiB free; 17.82 GiB reserved in total by PyTorch)\n",
      "error on step 310 CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 31.75 GiB total capacity; 16.29 GiB already allocated; 1.12 GiB free; 17.88 GiB reserved in total by PyTorch)\n",
      "error on step 311 CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 31.75 GiB total capacity; 16.29 GiB already allocated; 1.12 GiB free; 17.88 GiB reserved in total by PyTorch)\n",
      "error on step 315 CUDA out of memory. Tried to allocate 1.28 GiB (GPU 0; 31.75 GiB total capacity; 16.25 GiB already allocated; 1.12 GiB free; 17.88 GiB reserved in total by PyTorch)\n",
      "error on step 319 CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 31.75 GiB total capacity; 17.68 GiB already allocated; 26.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 325 CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 31.75 GiB total capacity; 17.95 GiB already allocated; 34.25 MiB free; 18.97 GiB reserved in total by PyTorch)\n",
      "error on step 326 CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 31.75 GiB total capacity; 18.07 GiB already allocated; 34.25 MiB free; 18.97 GiB reserved in total by PyTorch)\n",
      "epoch 1, step 328/593: train loss: 1.5286  val loss: 0.7372\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21977b51ae1406ab486ccfb97bb5563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on step 2 CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 31.75 GiB total capacity; 18.47 GiB already allocated; 74.25 MiB free; 18.93 GiB reserved in total by PyTorch)\n",
      "error on step 6 CUDA out of memory. Tried to allocate 1.32 GiB (GPU 0; 31.75 GiB total capacity; 15.57 GiB already allocated; 1.18 GiB free; 17.82 GiB reserved in total by PyTorch)\n",
      "error on step 9 CUDA out of memory. Tried to allocate 1.48 GiB (GPU 0; 31.75 GiB total capacity; 17.97 GiB already allocated; 386.25 MiB free; 18.62 GiB reserved in total by PyTorch)\n",
      "error on step 18 CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 31.75 GiB total capacity; 17.94 GiB already allocated; 120.25 MiB free; 18.88 GiB reserved in total by PyTorch)\n",
      "error on step 21 CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 31.75 GiB total capacity; 18.04 GiB already allocated; 232.25 MiB free; 18.78 GiB reserved in total by PyTorch)\n",
      "error on step 36 CUDA out of memory. Tried to allocate 1.33 GiB (GPU 0; 31.75 GiB total capacity; 17.13 GiB already allocated; 1.16 GiB free; 17.84 GiB reserved in total by PyTorch)\n",
      "error on step 44 CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 31.75 GiB total capacity; 18.03 GiB already allocated; 46.25 MiB free; 18.96 GiB reserved in total by PyTorch)\n",
      "error on step 62 CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 31.75 GiB total capacity; 16.29 GiB already allocated; 1.13 GiB free; 17.87 GiB reserved in total by PyTorch)\n",
      "error on step 75 CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 31.75 GiB total capacity; 17.62 GiB already allocated; 12.25 MiB free; 18.99 GiB reserved in total by PyTorch)\n",
      "error on step 93 CUDA out of memory. Tried to allocate 1.35 GiB (GPU 0; 31.75 GiB total capacity; 17.36 GiB already allocated; 940.25 MiB free; 18.08 GiB reserved in total by PyTorch)\n",
      "error on step 100 CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 31.75 GiB total capacity; 18.09 GiB already allocated; 64.25 MiB free; 18.94 GiB reserved in total by PyTorch)\n",
      "error on step 122 CUDA out of memory. Tried to allocate 1.24 GiB (GPU 0; 31.75 GiB total capacity; 17.73 GiB already allocated; 124.25 MiB free; 18.88 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 126 CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 31.75 GiB total capacity; 18.26 GiB already allocated; 270.25 MiB free; 18.74 GiB reserved in total by PyTorch)\n",
      "error on step 136 CUDA out of memory. Tried to allocate 1.20 GiB (GPU 0; 31.75 GiB total capacity; 17.05 GiB already allocated; 548.25 MiB free; 18.47 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 139 CUDA out of memory. Tried to allocate 1.25 GiB (GPU 0; 31.75 GiB total capacity; 17.05 GiB already allocated; 390.25 MiB free; 18.62 GiB reserved in total by PyTorch)\n",
      "error on step 155 CUDA out of memory. Tried to allocate 68.00 MiB (GPU 0; 31.75 GiB total capacity; 17.95 GiB already allocated; 6.25 MiB free; 19.00 GiB reserved in total by PyTorch)\n",
      "error on step 165 CUDA out of memory. Tried to allocate 1.19 GiB (GPU 0; 31.75 GiB total capacity; 16.96 GiB already allocated; 1012.25 MiB free; 18.01 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 166 CUDA out of memory. Tried to allocate 1.27 GiB (GPU 0; 31.75 GiB total capacity; 16.16 GiB already allocated; 986.25 MiB free; 18.04 GiB reserved in total by PyTorch)\n",
      "error on step 169 CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 31.75 GiB total capacity; 17.67 GiB already allocated; 110.25 MiB free; 18.89 GiB reserved in total by PyTorch)\n",
      "error on step 184 CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 31.75 GiB total capacity; 17.88 GiB already allocated; 4.25 MiB free; 19.00 GiB reserved in total by PyTorch)\n",
      "error on step 188 CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 16.53 GiB already allocated; 1.20 GiB free; 17.80 GiB reserved in total by PyTorch)\n",
      "error on step 189 CUDA out of memory. Tried to allocate 372.00 MiB (GPU 0; 31.75 GiB total capacity; 18.25 GiB already allocated; 358.25 MiB free; 18.65 GiB reserved in total by PyTorch)\n",
      "error on step 201 CUDA out of memory. Tried to allocate 1.23 GiB (GPU 0; 31.75 GiB total capacity; 17.63 GiB already allocated; 126.25 MiB free; 18.88 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 210 CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 17.19 GiB already allocated; 156.25 MiB free; 18.85 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 218 CUDA out of memory. Tried to allocate 1.33 GiB (GPU 0; 31.75 GiB total capacity; 17.03 GiB already allocated; 72.25 MiB free; 18.93 GiB reserved in total by PyTorch)\n",
      "error on step 261 CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 17.19 GiB already allocated; 72.25 MiB free; 18.93 GiB reserved in total by PyTorch)\n",
      "Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f374783f1e2 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1e64b (0x7f3747a9564b in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #2: <unknown function> + 0x1f464 (0x7f3747a96464 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: <unknown function> + 0x1faa1 (0x7f3747a96aa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f374a7bd52e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xf51329 (0x7f3748bf9329 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xf6b157 (0x7f3748c13157 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x10e9c7d (0x7f377f97dc7d in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x10e9f97 (0x7f377f97df97 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f377fa88a1a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7f377f706c3e in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x12880c1 (0x7f377fb1c0c1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x12c3863 (0x7f377fb57863 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7f377fa6bb31 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7f374a0491c7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7f374a0336da in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #16: <unknown function> + 0xf3efa0 (0x7f3748be6fa0 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #17: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: <unknown function> + 0x2ec639f (0x7f378175a39f in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: <unknown function> + 0x11141d6 (0x7f377f9a81d6 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7f377fa36649 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7f37815d6057 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #23: <unknown function> + 0x3375bb7 (0x7f3781c09bb7 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3781c05400 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3781c05fa1 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3781bfe119 in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f378f39ec8a in /home/user/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: <unknown function> + 0xcc9d4 (0x7f37e352d9d4 in /home/user/conda/bin/../lib/libstdc++.so.6)\n",
      "frame #29: <unknown function> + 0x76db (0x7f37e547e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #30: clone + 0x3f (0x7f37e47fa71f in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "error on step 263 CUDA out of memory. Tried to allocate 1.27 GiB (GPU 0; 31.75 GiB total capacity; 17.43 GiB already allocated; 34.25 MiB free; 18.97 GiB reserved in total by PyTorch)\n",
      "error on step 267 CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 31.75 GiB total capacity; 18.53 GiB already allocated; 24.25 MiB free; 18.98 GiB reserved in total by PyTorch)\n",
      "error on step 275 CUDA out of memory. Tried to allocate 118.00 MiB (GPU 0; 31.75 GiB total capacity; 18.11 GiB already allocated; 92.25 MiB free; 18.91 GiB reserved in total by PyTorch)\n",
      "error on step 280 CUDA out of memory. Tried to allocate 102.00 MiB (GPU 0; 31.75 GiB total capacity; 18.16 GiB already allocated; 14.25 MiB free; 18.99 GiB reserved in total by PyTorch)\n",
      "error on step 283 CUDA out of memory. Tried to allocate 1.28 GiB (GPU 0; 31.75 GiB total capacity; 17.53 GiB already allocated; 12.25 MiB free; 18.99 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "d = datasets['train']\n",
    "model = get_best_model(d['original'].tolist(),\n",
    "                        d['new'].tolist(),\n",
    "                        model_name=model_name,\n",
    "                        batch_size=16,\n",
    "                        lr=# use T5 lr,\n",
    "                        weight_decay=# use T5 wd,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ad77be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'../models/gpt_optuna_chekpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc8ddcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'sberbank-ai/rugpt3small_based_on_gpt2'\n",
    "# model_name = 't5_base_train_300'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b9de418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_special_tokens(\n",
    "    {'additional_special_tokens': [rephrase_token], 'pad_token': '[PAD]'}\n",
    ")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d73598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(text, model, n=None, max_length='auto', temperature=0.0, beams=3, repetition_penalty=1.0):\n",
    "    model.eval()\n",
    "    texts = [text] if isinstance(text, str) else text\n",
    "    inputs = tokenizer(texts, return_tensors='pt')['input_ids'].to(model.device)\n",
    "    if max_length == 'auto':\n",
    "        max_length = inputs.shape[1] * 2\n",
    "    result = model.generate(\n",
    "        inputs, \n",
    "        num_return_sequences=n or 1, \n",
    "        do_sample=False, \n",
    "        temperature=temperature, \n",
    "        repetition_penalty=repetition_penalty, \n",
    "        max_length=max_length,\n",
    "        bad_words_ids=[[2]],  # unk\n",
    "        num_beams=beams,\n",
    "        early_stopping=True,\n",
    "#         top_k=50,\n",
    "#         top_p=0.95,\n",
    "    )\n",
    "    texts = [tokenizer.decode(r, skip_special_tokens=True) for r in result]\n",
    "    if not n:\n",
    "        return texts[0][len(text[0])-len(rephrase_token):]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cf6ef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../evaluation/')\n",
    "from metrics import count_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b339e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['Начиная с премирования по итогам работы за январь 2021 г., руководствоваться перечнем операций и коэффициентами пересчета продуктов в условные продукты (далее - УП) для менеджеров по продажам в соответствии с Приложением к настоящему Распоряжению.',\n",
    "            'В случае подтверждения устранения Катастрофической или Серьезной ошибки Заказчик самостоятельно осуществляет тиражирование ПО в своих подразделениях и филиалах.',\n",
    "            'Контроль за исполнением настоящего Распоряжения оставляю за собой.',\n",
    "            'Утвердить перечень автоматизированных систем и информационных ресурсов Банка, доступных к подключению Cотрудникам (Приложение 1).']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ec9c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL: Начиная с премирования по итогам работы за январь 2021 г., руководствоваться перечнем операций и коэффициентами пересчета продуктов в условные продукты (далее - УП) для менеджеров по продажам в соответствии с Приложением к настоящему Распоряжению.\n",
      "REPHRASED:  Начиная с премирования по итогам работы за январь 2021 г., руководствоваться перечнем операций и коэффициентами пересчета продуктов в условные продукты (далее - УП) для менеджеров по продажам по Приложению к этому Распоряжению.\n",
      "####\n",
      "\n",
      "ORIGINAL: В случае подтверждения устранения Катастрофической или Серьезной ошибки Заказчик самостоятельно осуществляет тиражирование ПО в своих подразделениях и филиалах.\n",
      "REPHRASED:  При подтверждении устранения Катастрофической или Серьезной ошибки Заказчик самостоятельно тиражирует ПО в подразделениях и филиалах.\n",
      "####\n",
      "\n",
      "ORIGINAL: Контроль за исполнением настоящего Распоряжения оставляю за собой.\n",
      "REPHRASED:  Исполнение этого Распоряжения оставляю за собой.\n",
      "####\n",
      "\n",
      "ORIGINAL: Утвердить перечень автоматизированных систем и информационных ресурсов Банка, доступных к подключению Cотрудникам (Приложение 1).\n",
      "REPHRASED:  Установить перечень автоматизированных систем и информационных ресурсов Банка, доступных к подключению Cотрудникам (Приложение 1).\n",
      "####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_string in test_text:\n",
    "    print(f\"ORIGINAL: {test_string}\")\n",
    "    print(\"REPHRASED: \", paraphrase([test_string + rephrase_token], model,temperature=1, beams=10, repetition_penalty=10.0))\n",
    "    print(\"####\", end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
